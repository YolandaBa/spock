{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/ssd/miniconda3/envs/yba/lib/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
    "import hyperopt\n",
    "import sys\n",
    "sys.path.append('../spock/')\n",
    "from simsetup import get_sim\n",
    "from modelfitting import ROC_curve, stable_unstable_hist, calibration_plot, unstable_error_fraction\n",
    "from simsetup import get_sim\n",
    "try:\n",
    "    plt.style.use('paper')\n",
    "except:\n",
    "    pass\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../training_data/resonant/oldfeatures/\n",
      "../csvs/resonant/\n"
     ]
    }
   ],
   "source": [
    "datapath = '../training_data/'\n",
    "csvpath = '../csvs/'\n",
    "dset = 'resonant/'\n",
    "Norbits = 1e4\n",
    "Nout = 80\n",
    "featureargs = (Norbits, Nout) # params to pass feature function\n",
    "# featurefolder = 'featuresNorbits{0:.1f}Nout{1}trio/'.format(Norbits, Nout)\n",
    "featurefolder = 'oldfeatures/'.format(Norbits, Nout)\n",
    "trainingdatafolder = datapath+dset+featurefolder\n",
    "csvfolder = csvpath+dset\n",
    "print(trainingdatafolder)\n",
    "print(csvfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(trainingdatafolder+\"trainingdata.csv\", index_col = 0)\n",
    "labels = pd.read_csv(trainingdatafolder+\"labels.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intial condition folder here\n",
    "icfolder = \"/home/yba/spock/data/resonant/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_with_tmax = pd.read_csv(\"/home/yba/spock/training_data/resonant/labels_with_tmax.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cheating here\n",
    "dataset['tmax'] = labels_with_tmax['tmax']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasnull(row):\n",
    "    numnulls = row.isnull().sum()\n",
    "    if numnulls == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def tmax(row):\n",
    "    sim = get_sim(row, icfolder)\n",
    "    mtotal = sim.particles[1].m + sim.particles[2].m  + sim.particles[3].m\n",
    "    alpha13 = sim.particles[1].a / sim.particles[3].a \n",
    "    ec13 = 1-alpha13 \n",
    "    Tsec = 4* sim.particles[0].m/mtotal * ec13 * ec13  * sim.particles[3].P\n",
    "    Norbits = 5* Tsec\n",
    "    if Norbits > 10**6:\n",
    "        Norbits = 10**6\n",
    "    return Norbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near = ['EMcrossnear', 'EMfracstdnear', 'EPstdnear', 'MMRstrengthnear']\n",
    "far = ['EMcrossfar', 'EMfracstdfar', 'EPstdfar', 'MMRstrengthfar']\n",
    "megno = ['MEGNO', 'MEGNOstd']\n",
    "\n",
    "features = near + far + megno"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add columns for tmax and hasnull manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "if 'tmax' not in dataset.columns:\n",
    "    dataset['hasnull'] = dataset.apply(hasnull, axis=1)\n",
    "    # dataset['tmax'] = dataset.head(100).apply(tmax, axis=1)\n",
    "    # dataset['tmax'] = dataset.apply(lambda x:1e4, axis=1) # this version would just set tmax=1e4 for all of them\n",
    "\n",
    "    dataset.to_csv(trainingdatafolder+\"trainingdata.csv\", encoding='ascii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the filtering manually. This is taking only systems with instability times > 1e4 AND no NaNs. Would adjust this for each case. \n",
    "\n",
    "We were worried that we were using filter=..., which was filtering out any rows that had any NaNs in them. We wanted to compare results when we don't include that filter, and only filtered for instability_time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (labels['instability_time'] > dataset['tmax']) & (dataset['hasnull'] == 0)\n",
    "#mask = (labels['instability_time'] > labels['tmax']) & (dataset['hasnull'] == 0)\n",
    "y = labels[mask]['Stable']\n",
    "X = dataset[mask][features]\n",
    "tinst = labels[mask]['instability_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we do the train test split manually. We take 80\\% of the rows for training, 20\\% for testing (this is what we were doing before too)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Nrows = int(0.8*X.shape[0])\n",
    "trainX = X.iloc[:Nrows, :]\n",
    "trainY = y.iloc[:Nrows]\n",
    "testX = X.iloc[Nrows:, :]\n",
    "testY = y.iloc[Nrows:]\n",
    "test_tinst = tinst.iloc[Nrows:]\n",
    "\n",
    "dtrain = xgb.DMatrix(trainX, trainY)\n",
    "dtest = xgb.DMatrix(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space ={'max_depth': hp.qloguniform('x_max_depth', np.log(5), np.log(20), 1),\n",
    "        'min_child_weight': hp.loguniform('x_min_child', 0, np.log(20)),\n",
    "        'subsample': hp.uniform ('x_subsample', 0.8, 1),\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    clf = XGBClassifier(n_jobs=16, n_estimators = 50,\n",
    "                            max_depth = int(params['max_depth']), \n",
    "                            min_child_weight = params['min_child_weight'],\n",
    "                            subsample = params['subsample'],\n",
    "                            learning_rate = 0.15, seed = 0)\n",
    "    \n",
    "    score = xgb.cv(clf.get_xgb_params(), dtrain, nfold = 5, metrics = \"auc\", early_stopping_rounds=10)\n",
    "    avg_score =  np.mean(score[\"test-auc-mean\"])\n",
    "    error = np.mean(score[\"test-auc-std\"])\n",
    "    \n",
    "    print(\"SCORE:\", avg_score, \"ERROR\", error)#, \"HOLDOUT SCORE\", test_score)\n",
    "    return{'loss':1-avg_score, 'status': STATUS_OK, \"cv_score\":avg_score , \"cv_error\":error}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "import time\n",
    "start = time.time()\n",
    "best = fmin(fn=objective, space = space, algo = tpe.suggest, max_evals = 100, trials = trials, rstate=np.random.RandomState(seed=0))\n",
    "end = time.time()\n",
    "print(\"Optimization Time: %f seconds\", (end  -start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_depth controls depth of trees\n",
    "\n",
    "12 lets the model use all the features and improvements seem minor beyond that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = trials.vals['x_max_depth']\n",
    "min_childs = trials.vals['x_min_child']\n",
    "aucs = np.array([1-x['loss'] for x in trials.results])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(depths, aucs, '.')\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('CV AUC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# min child weight acts as a regularizer, penalizing complex models. Larger min_child_weight = larger penalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(min_childs, aucs, '.')\n",
    "ax.set_xlabel('min_child_weight')\n",
    "ax.set_ylabel('CV AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "cb = ax.scatter(depths, min_childs, c=aucs-0.93)\n",
    "plt.colorbar(cb, label='CV AUC - 0.93')\n",
    "ax.set_xlabel('max_depth')\n",
    "ax.set_ylabel('min_child_weight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marginal improvements beyond max_depth of 13, so choose the least complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(learning_rate = 0.03, \n",
    "                         max_depth = 20, \n",
    "                         subsample = 0.95,\n",
    "                         min_child_weight = 10)\n",
    "\n",
    "score = xgb.cv(model.get_xgb_params(), dtrain, nfold = 5, metrics = \"auc\", verbose_eval=True, num_boost_round=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going beyond ~100 trees does not improve CV, so cut off training there to avoid overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 100\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(score.index, score['train-auc-mean'], label='Train')\n",
    "ax.plot(score.index, score['test-auc-mean'], label='Test')\n",
    "ax.axvline(n_estimators, linestyle='--')\n",
    "ax.legend()\n",
    "ax.set_xlabel('n_estimators (num trees)')\n",
    "ax.set_ylabel('CV AUC score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_params(n_estimators = n_estimators)\n",
    "model.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model(datapath+'../spock/models/spock_fixtmaxfeature_tmax.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPOCK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each training data, need to load the corresponding dataset and model. Also need to change MASK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old version rebound - ic 10^4, filter 10^4 - origin paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "XGBoostError",
     "evalue": "[10:42:00] /croot/xgboost-split_1675119646044/work/include/xgboost/json.h:73: Invalid cast, from Integer to Boolean\nStack trace:\n  [bt] (0) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(+0x981e4) [0x7fd897aaa1e4]\n  [bt] (1) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::JsonBoolean const* xgboost::Cast<xgboost::JsonBoolean const, xgboost::Value const>(xgboost::Value const*)+0x310) [0x7fd897ae84b0]\n  [bt] (2) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::RegTree::LoadModel(xgboost::Json const&)+0x10ba) [0x7fd897cd71da]\n  [bt] (3) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::gbm::GBTreeModel::LoadModel(xgboost::Json const&)+0x63d) [0x7fd897bb17cd]\n  [bt] (4) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::gbm::GBTree::LoadModel(xgboost::Json const&)+0x185) [0x7fd897b9a2d5]\n  [bt] (5) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(+0x1bbc57) [0x7fd897bcdc57]\n  [bt] (6) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(XGBoosterLoadModel+0x7d4) [0x7fd897ac8714]\n  [bt] (7) /mnt/ssd/miniconda3/envs/yba/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x7fda6037a052]\n  [bt] (8) /mnt/ssd/miniconda3/envs/yba/lib/python3.10/lib-dynload/../../libffi.so.8(+0x88cd) [0x7fda603788cd]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m old_model \u001b[38;5;241m=\u001b[39m XGBClassifier()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mold_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatapath\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../spock/models/featureclassifier.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/ssd/miniconda3/envs/yba/lib/python3.10/site-packages/xgboost/sklearn.py:599\u001b[0m, in \u001b[0;36mXGBModel.load_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_Booster\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m Booster({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_jobs\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs})\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m meta_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_booster()\u001b[38;5;241m.\u001b[39mattr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscikit_learn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;66;03m# FIXME(jiaming): This doesn't have to be a problem as most of the needed\u001b[39;00m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;66;03m# information like num_class and objective is in Learner class.\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/ssd/miniconda3/envs/yba/lib/python3.10/site-packages/xgboost/core.py:2169\u001b[0m, in \u001b[0;36mBooster.load_model\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m   2166\u001b[0m     \u001b[38;5;66;03m# assume file name, cannot use os.path.exist to check, file can be\u001b[39;00m\n\u001b[1;32m   2167\u001b[0m     \u001b[38;5;66;03m# from URL.\u001b[39;00m\n\u001b[1;32m   2168\u001b[0m     fname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfspath(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexpanduser(fname))\n\u001b[0;32m-> 2169\u001b[0m     \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterLoadModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2171\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mbytearray\u001b[39m):\n\u001b[1;32m   2172\u001b[0m     buf \u001b[38;5;241m=\u001b[39m fname\n",
      "File \u001b[0;32m/mnt/ssd/miniconda3/envs/yba/lib/python3.10/site-packages/xgboost/core.py:218\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    208\u001b[0m \n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [10:42:00] /croot/xgboost-split_1675119646044/work/include/xgboost/json.h:73: Invalid cast, from Integer to Boolean\nStack trace:\n  [bt] (0) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(+0x981e4) [0x7fd897aaa1e4]\n  [bt] (1) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::JsonBoolean const* xgboost::Cast<xgboost::JsonBoolean const, xgboost::Value const>(xgboost::Value const*)+0x310) [0x7fd897ae84b0]\n  [bt] (2) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::RegTree::LoadModel(xgboost::Json const&)+0x10ba) [0x7fd897cd71da]\n  [bt] (3) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::gbm::GBTreeModel::LoadModel(xgboost::Json const&)+0x63d) [0x7fd897bb17cd]\n  [bt] (4) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(xgboost::gbm::GBTree::LoadModel(xgboost::Json const&)+0x185) [0x7fd897b9a2d5]\n  [bt] (5) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(+0x1bbc57) [0x7fd897bcdc57]\n  [bt] (6) /mnt/ssd/miniconda3/envs/yba/lib/libxgboost.so(XGBoosterLoadModel+0x7d4) [0x7fd897ac8714]\n  [bt] (7) /mnt/ssd/miniconda3/envs/yba/lib/python3.10/lib-dynload/../../libffi.so.8(+0xa052) [0x7fda6037a052]\n  [bt] (8) /mnt/ssd/miniconda3/envs/yba/lib/python3.10/lib-dynload/../../libffi.so.8(+0x88cd) [0x7fda603788cd]\n\n"
     ]
    }
   ],
   "source": [
    "old_model = XGBClassifier()\n",
    "old_model.load_model(datapath+'../spock/models/featureclassifier.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, fpr, tpr, ROCthresholds = ROC_curve(old_model, testX, testY)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC curve (AUC = {0:.3f})'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtmax_model = XGBClassifier()\n",
    "old_model.load_model(datapath+'../spock/models/spock_fixtmaxfeature_tmax.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### new rebound - integrate to tmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vary_tmax_model = XGBClassifier()\n",
    "vary_tmax_model.load_model(datapath+'../spock/models/featureclassifier.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, fpr, tpr, ROCthresholds = ROC_curve(vary_tmax_model, testX, testY)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC curve (AUC = {0:.3f})'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fix_tmax_model = XGBClassifier()\n",
    "new_fix_tmax_model.load_model(datapath+'../spock/models/spock_fixtmaxfeature_tmax.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc, fpr, tpr, ROCthresholds = ROC_curve(new_fix_tmax_model, testX, testY)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(fpr, tpr)\n",
    "ax.plot([0, 1], [0, 1], 'k--')\n",
    "ax.set_xlim([0.0, 1.0])\n",
    "ax.set_ylim([0.0, 1.0])\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('ROC curve (AUC = {0:.3f})'.format(roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 10\n",
    "np.savetxt('../spock/models/resROC.txt', (ROCthresholds[::stride], tpr[::stride], fpr[::stride]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROCthresholds, tpr, fpr = np.loadtxt('../spock/models/resROC.txt')\n",
    "for i in range(0,len(tpr), 15):\n",
    "    print(\"Threshold {0}, TPR = {1}, FPR = {2}\".format(ROCthresholds[i], tpr[i], fpr[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importances\n",
    "feat_imp = pd.Series(model.get_booster().get_fscore()).sort_values(ascending=False)\n",
    "ax = feat_imp.plot.barh(figsize=(12,8), fontsize=24)\n",
    "ax.set_xlabel('Feature Importance Score', fontsize=24)\n",
    "ax.invert_yaxis()\n",
    "plt.savefig('featureimportances.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, auc\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram:\n",
    "bins = 50\n",
    "Stable, Unstable = stable_unstable_hist(model, testX, testY)\n",
    "print(Unstable)\n",
    "\n",
    "fig, ax1 = plt.subplots()\n",
    "n, bins, patches = ax1.hist(Unstable, bins, alpha=0.5, label='No', color='blue', edgecolor = \"black\")\n",
    "ax1.set_xlabel('Predicted Probability', fontsize=14)\n",
    "ax1.set_ylabel('Unstable',  fontsize=14, color='blue')\n",
    "for tl in ax1.get_yticklabels():\n",
    "    tl.set_color('blue')\n",
    "    \n",
    "ax2 = ax1.twinx()\n",
    "n, bins , patches = ax2.hist(Stable, bins, alpha=0.5, label='Yes',color='green', edgecolor = \"black\")\n",
    "ax2.set_ylabel('Stable', fontsize=14, color='green')\n",
    "for tl in ax2.get_yticklabels():\n",
    "    tl.set_color('green')\n",
    "       \n",
    "ax1.set_ylim([0,35*n[-1]]) # goes up to ~4300\n",
    "ax2.set_ylim([0,1.1*n[-1]]) # goes up to ~2100\n",
    "fig.savefig('stable_unstable_comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bincenters, fracstable, errorbars = calibration_plot(model, testX, testY, bins=8)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(np.linspace(0,1,100), np.linspace(0,1,100), '--')\n",
    "ax.errorbar(bincenters, fracstable, errorbars)\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('Predicted Probability of Stability')\n",
    "ax.set_ylabel('Fraction actually stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.34 # for 10% FPR\n",
    "bincenters, errorfracs, errorbars = unstable_error_fraction(model, testX, testY, test_tinst, thresh, bins=10)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.errorbar(bincenters, errorfracs, errorbars)\n",
    "ax.set_ylim([0,1])\n",
    "ax.set_xlabel('Log Instability Time')\n",
    "ax.set_ylabel('Error Fraction')\n",
    "ax.set_title('Fraction of unstable systems mislabeled as stable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
